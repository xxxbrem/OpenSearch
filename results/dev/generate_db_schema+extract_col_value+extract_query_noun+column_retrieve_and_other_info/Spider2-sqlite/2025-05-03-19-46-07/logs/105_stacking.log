############################## Human at step extract_col_value ##############################

/* Some extract examples are provided based on similar problems: */
/* Answer the following: Please give the name of the course in which most numbers of the students got an A. Also, list the full name of the students who got an A in this course. most number of students got an A refers MAX(COUNT(student_id WHERE grade = 'A')); full name = f_name, l_name; got an A refers to grade = 'A'; */
#reason: The question requires display in order: "name of the course", "full name"."A" is filtering condition.
#columns: course.name, student.f_name, student.l_name, registration.grade, registration.student_id
#values: "A"

/* Answer the following:How much more votes for episode 1 than for episode 5? more votes refers to SUBTRACT(SUM(votes when episode = 1), SUM(votes when episode = 5)) */
#reason: The question requires display in order: "How much more vote". The definition of "more vote" is SUBTRACT(SUM(votes when episode = 1), SUM(votes when episode = 5)). 1, 5 are filtering conditions.
#columns: Episode.episode, Vote.votes
#values: "1", "5"

/* Answer the following: What is the average score of the movie "The Fall of Berlin" in 2019? Average score refers to Avg(rating_score); */
#reason: The question requires display in order: "average score". Average score is Avg(rating_score), "The Fall of Berlin",2019 are filtering conditions.
#columns: ratings.rating_score, ratings.rating_id, ratings.rating_timestamp_utc, movies.movie_title
#values: "The Fall of Berlin", "2019"

/* Answer the following: How many distinct orders were there in 2003 when the quantity ordered was less than 30? "year(orderDate) = '2003'; quantityOrdered < 30;" */
#reason:  The question requires display in order: "How many distinct orders"." in 2003", "less than 30" are filtering conditions.
#columns: orderdetails.orderNumber, orderdetails.quantityOrdered, orders.orderDate
#values: "30", "2003"

/* Answer the following: For order 423, what are the distinct product IDs together with the total quantity ordered for each? */
SELECT product_id,
       SUM(quantity) AS ordered_qty
FROM order_lines
WHERE order_id = 423
GROUP BY product_id;

/* Answer the following: For the products that appear on order 423, list every inventory location in warehouse 1, ordering them by oldest purchase_date and then by smallest on_hand quantity. */
SELECT I.product_id,
       I.id      AS location_id,
       I.aisle,
       I.position,
       I.on_hand,
       I.purchase_date
FROM inventory AS I
WHERE I.warehouse_id = 1
  AND I.product_id IN (SELECT product_id
                       FROM order_lines
                       WHERE order_id = 423)
ORDER BY I.purchase_date,
         I.on_hand;

/* Answer the following: Provide the cumulative ordered quantity after each line for products that appear more than once on order 423. */
SELECT line_number,
       product_id,
       quantity,
       SUM(quantity) OVER (PARTITION BY product_id
                           ORDER BY line_number) AS cumulative_qty
FROM order_lines
WHERE order_id = 423
ORDER BY line_number;

/* Answer the following: Which products on order 423 do not have enough inventory in warehouse 1 to cover the total ordered quantity? */
WITH ordered AS (
  SELECT product_id,
         SUM(quantity) AS ordered_qty
  FROM order_lines
  WHERE order_id = 423
  GROUP BY product_id
),
stock AS (
  SELECT product_id,
         SUM(on_hand) AS available_qty
  FROM inventory
  WHERE warehouse_id = 1
  GROUP BY product_id
)
SELECT o.product_id
FROM ordered AS o
LEFT JOIN stock AS s
       ON s.product_id = o.product_id
WHERE COALESCE(s.available_qty,0) < o.ordered_qty;

/* Answer the following: For product 205 on order 423, return the first inventory location from which picking should start (oldest purchase_date and smallest on_hand in warehouse 1). */
SELECT id    AS location_id,
       aisle,
       position,
       on_hand
FROM inventory
WHERE warehouse_id = 1
  AND product_id = 205
ORDER BY purchase_date,
         on_hand
LIMIT 1;



/* Database schema */
Database Management System: SQLite
#Database name: stacking
## Table problem:
name: The type is TEXT, Which does not inlude Null and is Unique. Values format like: ['PSS3E5', 'Tunnel diode', 'water quality 2']
path: The type is TEXT, Which does not inlude Null and is Unique. Values format like: ['https://www.kaggle.com/datasets/muratkokludataset/pumpkin-seeds-dataset', 'https://www.kaggle.com/datasets/mssmartypants/water-quality', 'https://www.kaggle.com/datasets/prasoonkottarathil/polycystic-ovary-syndrome-pcos']
type: The type is TEXT, Which does not inlude Null and is Non-Unique. Value of this column must in: ['classification', 'regression']
target: The type is TEXT, Which does not inlude Null and is Non-Unique. Values format like: ['Outcome', 'outcome', 'Power Generated']

## Table eda:
name: The type is TEXT, Which does not inlude Null and is Non-Unique. Values format like: ['kindey stone urine analysis', 'Tunnel diode', 'iris']
version: The type is INTEGER, Which does not inlude Null and is Non-Unique. Values format like: [5, 1, 7]
feature: The type is TEXT, Which does not inlude Null and is Non-Unique. Values format like: ['AromaticProportion', 'density', 'f_13']
type: The type is TEXT, Which inlude Null and is Non-Unique. Value of this column must in: ['num', 'cat']
range: The type is BLOB, Which inlude Null and is Non-Unique. Values format like: ['[0, 122]', '[0.0, 19.83]', '[80.26666667, 122.5263158]']
drop_user: The type is INTEGER, Which does not inlude Null and is Non-Unique. Value of this column must in: [0, 1]
drop_correlation: The type is INTEGER, Which does not inlude Null and is Non-Unique. Value of this column must in: [0, 1]
target: The type is INTEGER, Which does not inlude Null and is Non-Unique. Value of this column must in: [0, 1]

## Table feature_importance:
name: The type is TEXT, Which does not inlude Null and is Non-Unique. Values format like: ['PCOS', 'iris', 'smoke detection iot']
version: The type is INTEGER, Which does not inlude Null and is Non-Unique. Values format like: [7, 3, 6]
step: The type is INTEGER, Which does not inlude Null and is Non-Unique. Values format like: [1, 3, 2]
feature: The type is TEXT, Which does not inlude Null and is Non-Unique. Values format like: ['Average Wind Direction (Day)', 'f_37', 'coarseaggregate']
importance: The type is NUMERIC, Which does not inlude Null and is Non-Unique. Values format like: [0, 0, 0]

## Table solution:
name: The type is TEXT, Which does not inlude Null and is Non-Unique. Values format like: ['oil spill', 'Solar Power Generation', 'water quality']
version: The type is INTEGER, Which does not inlude Null and is Non-Unique. Values format like: [5, 1, 6]
correlation: The type is NUMERIC, Which does not inlude Null and is Non-Unique. Value of this column must in: [0]
nb_model: The type is INTEGER, Which does not inlude Null and is Non-Unique. Values format like: [7, 6, 5]
nb_feature: The type is INTEGER, Which does not inlude Null and is Non-Unique. Values format like: [5, 6, 4]
score: The type is NUMERIC, Which does not inlude Null and is Non-Unique. Values format like: [0, 0, 0]
test_size: The type is NUMERIC, Which does not inlude Null and is Non-Unique. Values format like: [0, 0, 0]
resampling: The type is INTEGER, Which does not inlude Null and is Non-Unique. Value of this column must in: [0, 1]

## Table model_score:
name: The type is TEXT, Which does not inlude Null and is Non-Unique. Values format like: ['Critical Heat Flux', 'lithium ion batteries', 'Solar Power Generation']
version: The type is INTEGER, Which does not inlude Null and is Non-Unique. Values format like: [8, 3, 7]
step: The type is INTEGER, Which does not inlude Null and is Non-Unique. Values format like: [2, 1, 3]
model: The type is TEXT, Which does not inlude Null and is Non-Unique. Values format like: ['SVCS', 'MLPR2', 'RFCG']
train_score: The type is NUMERIC, Which does not inlude Null and is Non-Unique. Values format like: [0, 0, 0]
test_score: The type is NUMERIC, Which does not inlude Null and is Non-Unique. Values format like: [0, 0, 0]

## Table model_importance:
name: The type is TEXT, Which does not inlude Null and is Non-Unique. Values format like: ['Critical Heat Flux', 'kindey stone urine analysis', 'PSS3E5']
version: The type is INTEGER, Which does not inlude Null and is Non-Unique. Values format like: [2, 4, 5]
step: The type is INTEGER, Which does not inlude Null and is Non-Unique. Values format like: [1, 3, 2]
model: The type is TEXT, Which does not inlude Null and is Non-Unique. Values format like: ['GPCR', 'RFRS', 'ABR']
importance: The type is NUMERIC, Which does not inlude Null and is Non-Unique. Values format like: [0, 0, 0]

## Table model:
name: The type is TEXT, Which does not inlude Null and is Non-Unique. Values format like: ['diabetes', 'iris', 'PCOS']
version: The type is INTEGER, Which does not inlude Null and is Non-Unique. Values format like: [4, 6, 5]
step: The type is INTEGER, Which does not inlude Null and is Non-Unique. Values format like: [2, 1, 3]
L1_model: The type is TEXT, Which does not inlude Null and is Non-Unique. Value of this column must in: ['regression', 'tree']

#Forigen keys:


# Database Description:
The database named "stacking" is designed to manage and analyze datasets, models, and solutions related to machine learning and data science workflows. It includes information about datasets, exploratory data analysis (EDA), feature importance, solutions, model scores, model importance, and models. The database is implemented using SQLite and contains multiple tables with specific attributes and constraints.

# Tables Descriptions:

## Table: problem
- **Description**: Contains information about datasets used for machine learning tasks.
- **Columns**:
  - `name`: TEXT, Not NULL, Unique. Example values: ['PSS3E5', 'Tunnel diode', 'water quality 2'].
  - `path`: TEXT, Not NULL, Unique. Example values: ['https://www.kaggle.com/datasets/muratkokludataset/pumpkin-seeds-dataset', 'https://www.kaggle.com/datasets/mssmartypants/water-quality'].
  - `type`: TEXT, Not NULL, Non-Unique. Must be one of ['classification', 'regression'].
  - `target`: TEXT, Not NULL, Non-Unique. Example values: ['Outcome', 'outcome', 'Power Generated'].

## Table: eda
- **Description**: Contains information about exploratory data analysis (EDA) performed on datasets.
- **Columns**:
  - `name`: TEXT, Not NULL, Non-Unique. Example values: ['kindey stone urine analysis', 'Tunnel diode', 'iris'].
  - `version`: INTEGER, Not NULL, Non-Unique. Example values: [5, 1, 7].
  - `feature`: TEXT, Not NULL, Non-Unique. Example values: ['AromaticProportion', 'density', 'f_13'].
  - `type`: TEXT, Nullable, Non-Unique. Must be one of ['num', 'cat'].
  - `range`: BLOB, Nullable, Non-Unique. Example values: ['[0, 122]', '[0.0, 19.83]', '[80.26666667, 122.5263158]'].
  - `drop_user`: INTEGER, Not NULL, Non-Unique. Must be one of [0, 1].
  - `drop_correlation`: INTEGER, Not NULL, Non-Unique. Must be one of [0, 1].
  - `target`: INTEGER, Not NULL, Non-Unique. Must be one of [0, 1].

## Table: feature_importance
- **Description**: Contains information about the importance of features in datasets.
- **Columns**:
  - `name`: TEXT, Not NULL, Non-Unique. Example values: ['PCOS', 'iris', 'smoke detection iot'].
  - `version`: INTEGER, Not NULL, Non-Unique. Example values: [7, 3, 6].
  - `step`: INTEGER, Not NULL, Non-Unique. Example values: [1, 3, 2].
  - `feature`: TEXT, Not NULL, Non-Unique. Example values: ['Average Wind Direction (Day)', 'f_37', 'coarseaggregate'].
  - `importance`: NUMERIC, Not NULL, Non-Unique. Example values: [0, 0, 0].

## Table: solution
- **Description**: Contains information about solutions applied to datasets.
- **Columns**:
  - `name`: TEXT, Not NULL, Non-Unique. Example values: ['oil spill', 'Solar Power Generation', 'water quality'].
  - `version`: INTEGER, Not NULL, Non-Unique. Example values: [5, 1, 6].
  - `correlation`: NUMERIC, Not NULL, Non-Unique. Must be [0].
  - `nb_model`: INTEGER


Attention:
1. if the question have when\where\which, pay attention to pick table.column related to time, location and name in #columns
2. Please answer the question in the following format without any other content:
```
#reason: Analysis of which columns and values might be relevant to the question. Note that when dealing with questions about time, who, which, what, etc., you should keep column related to time, names, and locations in the #column.(format: The question query xxx, the related column include table.column, the values include values)
#columns: The top 10 columns relevant to the question( format: table.column_1, table.column_2 ...)
#values: Potential filter values that the question might query(format: "value1", "value2" ...)
```
/* Answer the following: Identify the L1_model associated with each model (specified by name and version) that occurs most frequently for each status ('strong' or 'soft'), along with the number of times it occurs. A model has a 'strong' status if, for any of its steps, the maximum test score among non-'Stack' models is less than the 'Stack' model's test score. It has a 'soft' status if the maximum test score among non-'Stack' models equals the 'Stack' model's test score. Count how many times each L1_model is associated with a 'strong' or 'soft' status across all models, and determine which L1_model has the highest occurrence for each status. */


############################## AI at step extract_col_value ##############################

```
#reason: The question queries the L1_model associated with each model (specified by name and version) and its occurrence for statuses ('strong' or 'soft'). The related columns include model.name, model.version, model.L1_model, model_score.model, model_score.test_score, model_score.step. The values include "Stack", "strong", "soft".
#columns: model.name, model.version, model.L1_model, model_score.model, model_score.test_score, model_score.step
#values: "Stack", "strong", "soft"
```

############################## Human at step extract_query_noun ##############################

Please extract all nouns and phrases from the following sentence, separating the results directly with a comma( format: "noun_1", "noun_2","phrases" ):
Identify the L1_model associated with each model (specified by name and version) that occurs most frequently for each status ('strong' or 'soft'), along with the number of times it occurs. A model has a 'strong' status if, for any of its steps, the maximum test score among non-'Stack' models is less than the 'Stack' model's test score. It has a 'soft' status if the maximum test score among non-'Stack' models equals the 'Stack' model's test score. Count how many times each L1_model is associated with a 'strong' or 'soft' status across all models, and determine which L1_model has the highest occurrence for each status.

############################## AI at step extract_query_noun ##############################

"L1_model", "model", "name", "version", "status", "strong", "soft", "number of times", "test score", "non-'Stack' models", "'Stack' model", "steps", "highest occurrence", "occurrence", "all models", "each status"

############################## Human at step column_retrieve_and_other_info ##############################

现在我们定义一个问句的语法原子单元如下:
Q: 询问词: 如 calculate\ Include\ List\ List out\ List all\ give\ state\ Name\ In which\ How many\  which\ what\ who\ when\ provide\ Tally\ identify\ Find\ mention\ write等
J: 判断词： 如 Do\ Did\ If\ Is\ Are等
I: 查询内容: 查询的主体内容, 如: name, ID, date, location, item, biggest city.
C: 条件句: 通过介词和连词引入的查询的要求或属性, 如大于、等于、排序、聚合等. 介词和连词有: of\ have\ with\ that\ by. 条件句的形式例子有: with condition\ have condition\ of attribute\ that was condition


一个问题通过这些原子串联起来。常见的串联方式有
QIC(询问句): List the student with score more than 80: Q: 'List' I: 'the student' C: 'with score more than 80'
JC(判断句): State if Tom is a Cat? : J: 'State if C: is a Cat?'
C(条件句): For all people in Beijing
现在请你针对下面的问题, 把问题中的内容按照上述原子定义提取出来
问题如下: Identify the L1_model associated with each model (specified by name and version) that occurs most frequently for each status ('strong' or 'soft'), along with the number of times it occurs. A model has a 'strong' status if, for any of its steps, the maximum test score among non-'Stack' models is less than the 'Stack' model's test score. It has a 'soft' status if the maximum test score among non-'Stack' models equals the 'Stack' model's test score. Count how many times each L1_model is associated with a 'strong' or 'soft' status across all models, and determine which L1_model has the highest occurrence for each status.

请按照下面的json格式进行回答:

```json
[{"Type":"类型(QIC,JC,C)",
"Extract":{//不存在的填null
    "Q":"询问词",
    "J":"判断词",
    "I":['查询内容a', '查询内容b'],//只有查询内容用and或alongside连接时,才分成多个实体填入List
    "C":["条件句a","属性b"]
}},
{}]
```

############################## AI at step column_retrieve_and_other_info ##############################

```json
[
    {
        "Type": "QIC",
        "Extract": {
            "Q": "Identify",
            "J": null,
            "I": ["the L1_model associated with each model"],
            "C": [
                "specified by name and version",
                "that occurs most frequently for each status ('strong' or 'soft')",
                "along with the number of times it occurs"
            ]
        }
    },
    {
        "Type": "C",
        "Extract": {
            "Q": null,
            "J": null,
            "I": null,
            "C": [
                "A model has a 'strong' status if, for any of its steps, the maximum test score among non-'Stack' models is less than the 'Stack' model's test score",
                "It has a 'soft' status if the maximum test score among non-'Stack' models equals the 'Stack' model's test score"
            ]
        }
    },
    {
        "Type": "QIC",
        "Extract": {
            "Q": "Count",
            "J": null,
            "I": ["how many times each L1_model is associated with a 'strong' or 'soft' status across all models"],
            "C": null
        }
    },
    {
        "Type": "QIC",
        "Extract": {
            "Q": "Determine",
            "J": null,
            "I": ["which L1_model has the highest occurrence for each status"],
            "C": null
        }
    }
]
```

